# Native Fetch Streaming Implementation

## ğŸ¯ Váº¥n Ä‘á»

`GM.xmlHttpRequest` trong Tampermonkey **khÃ´ng trigger `readyState 3`** vÃ  **`onprogress` cÅ©ng khÃ´ng hoáº¡t Ä‘á»™ng**, khiáº¿n streaming bá»‹ máº¥t.

## âœ… Giáº£i phÃ¡p

Sá»­ dá»¥ng **native `fetch` API** vá»›i `ReadableStream` cho providers há»— trá»£ CORS.

## ğŸ“ Files Created

### 1. `src/utils/llm-fetch.ts`
Native fetch implementation vá»›i streaming tháº­t sá»±.

**Features:**
- âœ… Streaming qua `ReadableStream`
- âœ… SSE (Server-Sent Events) parsing
- âœ… Proper error handling
- âœ… Sync & Stream convenience functions
- âœ… CORS testing utility

### 2. `src/utils/llm-smart.ts`
Smart wrapper tá»± Ä‘á»™ng chá»n giá»¯a fetch vÃ  GM.

**Features:**
- âœ… Auto-detect CORS support
- âœ… Cache CORS test results
- âœ… Fallback to GM if fetch fails
- âœ… Prefer fetch for streaming (better support)

## ğŸ”§ Changes Made

### ChatScreen.vue
```typescript
// TRÆ¯á»šC
import { sendOpenAiRequestStream } from '@/utils/llm';

// SAU
import { sendOpenAiRequestFetchStream } from '@/utils/llm-fetch';
```

## ğŸ“Š Comparison

### GM.xmlHttpRequest (Old)
```
âŒ readyState 3 khÃ´ng trigger
âŒ onprogress khÃ´ng hoáº¡t Ä‘á»™ng
âŒ Pháº£i chá» response hoÃ n thÃ nh
âŒ KhÃ´ng streaming tháº­t sá»±
```

### Native Fetch (New)
```
âœ… ReadableStream hoáº¡t Ä‘á»™ng
âœ… Chunks Ä‘Æ°á»£c nháº­n realtime
âœ… Streaming tháº­t sá»±
âœ… Chá»¯ xuáº¥t hiá»‡n tá»«ng chá»¯ má»™t
```

## ğŸŒ Provider Compatibility

### âœ… CORS-Enabled (Use Fetch)
- **OpenAI**: `https://api.openai.com/v1`
- **Groq**: `https://api.groq.com/openai/v1`
- **Together AI**: `https://api.together.xyz/v1`
- **Local Ollama**: `http://localhost:11434/v1`
- **Local LM Studio**: `http://localhost:1234/v1`

### âŒ CORS-Blocked (Use GM)
- **Anthropic**: `https://api.anthropic.com` (blocked)
- **Some proxies**: Depends on configuration

## ğŸš€ Usage

### Option 1: Direct Fetch (Recommended for CORS providers)
```typescript
import { sendOpenAiRequestFetchStream } from '@/utils/llm-fetch';

await sendOpenAiRequestFetchStream(options, (chunk) => {
  console.log(chunk); // Realtime streaming!
});
```

### Option 2: Smart Auto-Select
```typescript
import { sendOpenAiRequestSmartStream } from '@/utils/llm-smart';

// Auto-detect CORS and choose best method
await sendOpenAiRequestSmartStream(options, (chunk) => {
  console.log(chunk);
});
```

### Option 3: Force GM (For non-CORS providers)
```typescript
import { sendOpenAiRequestStream } from '@/utils/llm';

// Use GM.xmlHttpRequest (no streaming, but works with CORS-blocked)
await sendOpenAiRequestStream(options, (chunk) => {
  console.log(chunk);
});
```

## ğŸ§ª Testing

### Test CORS Support
```typescript
import { testCORS } from '@/utils/llm-fetch';

const supportsCORS = await testCORS(
  'https://api.openai.com/v1',
  'sk-...'
);

console.log(supportsCORS); // true or false
```

### Test Streaming
1. Open DevTools Console
2. Send a chat message
3. Look for logs:
   - `âœ… Fetch stream finished successfully` â†’ Streaming works!
   - Chunks appearing in realtime â†’ Success!

## ğŸ“ Code Flow

### Fetch Streaming Flow
```
1. fetch(apiURL, { stream: true })
   â†“
2. response.body.getReader()
   â†“
3. while (true) { reader.read() }
   â†“
4. Decode chunk â†’ Parse SSE â†’ Extract content
   â†“
5. onChunk(content) â†’ UI updates REALTIME âœ¨
   â†“
6. done? â†’ Break loop
```

### SSE Parsing
```
Raw chunk:
"data: {\"choices\":[{\"delta\":{\"content\":\"Hello\"}}]}\n\n"

After parsing:
â†’ content = "Hello"
â†’ onChunk("Hello")
â†’ UI shows "Hello" immediately
```

## âš ï¸ Limitations

### Fetch API
- âŒ Blocked by CORS if provider doesn't allow
- âœ… Streaming works perfectly
- âœ… Modern browsers only

### GM.xmlHttpRequest
- âœ… Bypasses CORS
- âŒ Streaming doesn't work (Tampermonkey limitation)
- âœ… Works in all Userscript managers

## ğŸ¯ Recommendation

1. **Use Fetch** for providers that support CORS (OpenAI, Groq, Ollama, etc.)
2. **Use GM** only for CORS-blocked providers (Anthropic, some proxies)
3. **Avoid providers** that both block CORS AND you need streaming

## ğŸ“ˆ Performance

### Before (GM without streaming)
```
Request â†’ Wait 10s â†’ Full response appears
User experience: ğŸ˜´ Boring, feels slow
```

### After (Fetch with streaming)
```
Request â†’ Chunk 1 (0.1s) â†’ Chunk 2 (0.2s) â†’ ... â†’ Done
User experience: ğŸ¤© Exciting, feels fast!
```

## ğŸ” Debugging

### If streaming doesn't work:
1. Check console for `âœ… Fetch stream finished successfully`
2. If not, check for CORS errors
3. If CORS error, switch to GM or use CORS proxy
4. If fetch works but no chunks, check SSE parsing logic

### Common Issues:
- **CORS error**: Provider doesn't support CORS â†’ Use GM
- **No chunks**: Provider not sending SSE format â†’ Check API docs
- **Slow streaming**: Network issue, not code issue

---

**Implemented**: 2025-12-04 19:41  
**Status**: âœ… WORKING (for CORS-enabled providers)
